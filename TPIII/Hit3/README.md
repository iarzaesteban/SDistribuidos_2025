# üìã README para Hit3

# üìö Tabla de Contenidos

- [Objetivo General](#objetivo-general)
- [Deploy](#deploy)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [Dise√±o de Arquitectura](#dise√±o-de-arquitectura)
- [Backend](#backend)
- [Worker](#worker)
- [Frontend](#frontend)
- [Comunicacion Distribuida: RabbitMQ y Redis](#comunicacion-distribuida-rabbitmq-y-redis)
- [Contenerizacion de Servicios con Docker](#contenarizacion-de-servicios-con-docker)
- [Orquestacion con Kubernetes](#Ô∏è-orquestacion-con-kubernetes)
- [Infraestructura como Codigo (IaC) con Terraform](#Ô∏è-infraestructura-como-codigo-iac-con-terraform)
- [Automatizacion de Despliegue](#automatizacion-de-despliegue)
- [Pruebas de Rendimiento](#pruebas-de-rendimiento)
- [Resultados y Conclusiones](#resultados-y-conclusiones)
- [Health Check y Logs](#health-check-y-logs)
- [Escalabilidad](#escalabilidad)


## Objetivo General

El presente proyecto tiene como objetivo dise√±ar y desplegar una plataforma distribuida para el procesamiento de im√°genes mediante el filtro de Sobel, basada en tecnolog√≠as de contenedores y orquestada en un entorno cloud escalable.

A diferencia de soluciones anteriores de cl√∫steres locales, en este caso se implementa una infraestructura en la nube utilizando Google Kubernetes Engine (GKE) como base, siguiendo las siguientes directrices:

1. Despliegue de cl√∫ster Kubernetes mediante Terraform, automatizando la provisi√≥n de:

- Un node pool espec√≠fico para alojar servicios de infraestructura como RabbitMQ (sistema de colas) y Redis (sistema de notificaciones).

- Un node pool destinado a las aplicaciones del sistema: frontend, backend, workers de procesamiento.

2. Separaci√≥n de procesamiento intensivo: los procesos de c√≥mputo pesado (aplicaci√≥n del filtro Sobel) son ejecutados en m√°quinas virtuales externas al cl√∫ster de Kubernetes, permitiendo un escalado independiente y optimizado.

3. Automatizaci√≥n de despliegues: construcci√≥n de pipelines que incluyen:

- Pipeline 1: Creaci√≥n del cl√∫ster Kubernetes.

- Pipeline 1.1: Despliegue de servicios de infraestructura (RabbitMQ y Redis).

- Pipeline 1.2 - 1.N: Despliegue individual de cada aplicaci√≥n (frontend, backend, worker).

- Pipeline 2: Provisi√≥n de m√°quinas virtuales para workers, buscando escalabilidad din√°mica.

4. An√°lisis de desempe√±o bajo carga: se realizan pruebas de benchmarking modificando:

- Tama√±o de las im√°genes procesadas.

- Nivel de concurrencia de peticiones.

- Cantidad de workers disponibles.

Los resultados obtenidos permiten evaluar la escalabilidad, eficiencia y capacidad de respuesta del sistema ante diferentes condiciones de uso.

## Deploy

Para poder correr el proyecto:

```bash
  make deploy
  .\deploy_all.ps1
```

Para finalizar y liberar recursos:

```bash
  make destroy
```

## Estructura del Repositorio

La estructura de carpetas del proyecto es la siguiente:

```bash

/Hit3/
‚îú‚îÄ‚îÄ backend/                  # Servicio Backend (FastAPI) que coordina el procesamiento
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ frontend/                 # Interfaz web del usuario y servidor Nginx
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf
‚îÇ
‚îú‚îÄ‚îÄ worker/                   # Servicio Worker que aplica el filtro Sobel
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ worker.py
‚îÇ
‚îú‚îÄ‚îÄ infra/                    # Infraestructura como c√≥digo (Terraform)
‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfstate
‚îÇ   ‚îú‚îÄ‚îÄ .terraform/           # Archivos internos de Terraform
‚îÇ   ‚îî‚îÄ‚îÄ workers/              # M√≥dulo espec√≠fico para m√°quinas de procesamiento externo
‚îÇ       ‚îú‚îÄ‚îÄ main.tf
‚îÇ       ‚îú‚îÄ‚îÄ variables.tf
‚îÇ       ‚îú‚îÄ‚îÄ terraform.tfvars
‚îÇ       ‚îî‚îÄ‚îÄ terraform.tfstate
‚îÇ
‚îú‚îÄ‚îÄ k8s_actualizados/         # Manifiestos Kubernetes para despliegue de servicios
‚îÇ   ‚îú‚îÄ‚îÄ backend-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ backend-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ backend-service-external.yaml
‚îÇ   ‚îú‚îÄ‚îÄ frontend-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ frontend-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ nginx-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ nginx-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ rabbitmq-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ rabbitmq-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ redis-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ redis-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ worker-deployment.yaml
‚îÇ   ‚îî‚îÄ‚îÄ worker-hpa.yaml
‚îÇ
‚îú‚îÄ‚îÄ test_images/              # Im√°genes utilizadas para pruebas de benchmarking
‚îÇ   ‚îú‚îÄ‚îÄ 1024KB.jpg
‚îÇ   ‚îî‚îÄ‚îÄ 10240KB.jpg
‚îÇ
‚îú‚îÄ‚îÄ analisis_rendimiento_sobel.md   # An√°lisis del rendimiento obtenido
‚îú‚îÄ‚îÄ benchmark_results.csv           # Datos de benchmark
‚îú‚îÄ‚îÄ benchmark_result_plot.png       # Gr√°fico con resultados
‚îú‚îÄ‚îÄ generar_grafico_benchmark.py    # Script para generar el gr√°fico
‚îú‚îÄ‚îÄ deploy_all.ps1                  # Script de despliegue automatizado (PowerShell)
‚îú‚îÄ‚îÄ Makefile                        # Comandos √∫tiles de automatizaci√≥n
‚îú‚îÄ‚îÄ test_sender.py                  # Script de pruebas de carga
‚îú‚îÄ‚îÄ test_benchmark.py               # Script de pruebas espec√≠ficas
‚îú‚îÄ‚îÄ terraform.tfstate               # Estado de Terraform general
‚îú‚îÄ‚îÄ README.md                       # Documentaci√≥n del proyecto
‚îî‚îÄ‚îÄ test.jpg                        # Imagen de prueba manual

```

## Dise√±o de Arquitectura

El sistema est√° compuesto por m√∫ltiples servicios distribuidos, organizados en una arquitectura asincr√≥nica y escalable. El flujo principal de procesamiento es el siguiente:

```bash

[ Usuario ]
     |
     v
[ Frontend (Nginx + HTML) ]
     |
     v
[ Backend (FastAPI) ]
     |
     v
[ Divide Imagen + Encola tareas en RabbitMQ ]
     |
     v
[ Workers (en VMs externas) ]
     |
     v
[ Resultado parcial a Redis ]
     |
     v
[ Backend reconstruye imagen ]
     |
     v
[ Frontend muestra resultado final ]

```

Otros componentes del sistema:

- üîÅ RabbitMQ: cola de tareas de procesamiento.

- üì¨ Redis: notificaci√≥n de finalizaci√≥n mediante Pub/Sub.

- ‚ò∏Ô∏è Kubernetes (GKE): orquesta frontend, backend, Redis y RabbitMQ.

- üñ•Ô∏è VMs externas: ejecutan los workers fuera del cl√∫ster.


```mermaid
flowchart TD
 subgraph Usuario["Usuario"]
        A1["Usuario en navegador"]
  end
 subgraph Frontend["Nginx"]
        B1["Formulario HTML para subir imagen"]
        B2["Consulta resultado procesado"]
  end
 subgraph Backend["FastAPI"]
        C1["Recibe imagen"]
        C2["Divide imagen en fragmentos"]
        C3["Encola tareas en RabbitMQ"]
        C4["Escucha Redis Pub/Sub"]
        C5["Reconstruye imagen final"]
        C6["Sirve resultado procesado"]
  end
 subgraph RabbitMQ["Cola de mensajes"]
        D1["Cola de tareas de fragmentos"]
  end
 subgraph Workers["VMs Externas"]
        E1["Worker escucha cola"]
        E2["Procesa fragmento - Filtro Sobel"]
        E3["Publica resultado en Redis"]
  end
 subgraph Redis["Pub/Sub"]
        F1["Canal Pub/Sub por imagen"]
  end
 subgraph subGraph6["Kubernetes Cluster"]
        G1["Node Pool Infraestructura"]
        G2["Node Pool Aplicaciones"]
  end
    A1 --> B1
    B1 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> D1
    D1 --> E1
    E1 --> E2
    E2 --> E3
    E3 --> F1
    F1 --> C4
    C4 --> C5
    C5 --> C6
    C6 --> B2
    B2 --> A1
    G1 --> D1 & F1
    G2 --> B1 & C1


```





### Explicacion del Flujo

El flujo de trabajo comienza cuando el usuario sube una imagen a trav√©s del **Frontend**, una interfaz simple servida por Nginx.  
Esta imagen es enviada al **Backend**, que act√∫a como coordinador central del sistema.

El Backend divide la imagen en partes y encola cada tarea en **RabbitMQ**, permitiendo una distribuci√≥n asincr√≥nica del trabajo.  
Las tareas son consumidas por los **Workers**, que se ejecutan en **m√°quinas virtuales externas** al cl√∫ster de Kubernetes.  
Cada Worker aplica el **filtro de Sobel** a su porci√≥n asignada.

Una vez finalizado el procesamiento, cada Worker publica su resultado en **Redis** mediante un canal de *Pub/Sub*.  
Cuando el Backend detecta que todas las partes fueron procesadas, reconstruye la imagen completa.

Finalmente, el resultado es reenviado al Frontend, donde el usuario puede visualizar la imagen procesada.

Este dise√±o desacopla los componentes, favorece la paralelizaci√≥n y permite escalar horizontalmente tanto el procesamiento como los servicios.

## Backend

El Backend es el n√∫cleo l√≥gico del sistema. Est√° desarrollado en **Python** utilizando el framework **FastAPI**, lo cual permite definir servicios web de forma sencilla, robusta y con gran rendimiento asincr√≥nico.

### üéØ Funcionalidad principal

El Backend cumple m√∫ltiples roles:

- **Recepci√≥n de im√°genes** desde el Frontend a trav√©s de un endpoint HTTP (`/upload`).
- **Divisi√≥n de la imagen** en partes iguales, seg√∫n la cantidad de Workers disponibles.
- **Encolado de tareas** en **RabbitMQ**, enviando un mensaje por cada porci√≥n de la imagen.
- **Escucha de Redis** por eventos de finalizaci√≥n, a trav√©s de **Pub/Sub**, para saber cu√°ndo todos los Workers terminaron.
- **Reensamblado de la imagen final**, uniendo todas las partes procesadas por los Workers.
- **Env√≠o del resultado** al Frontend mediante un endpoint (`/result/{image_id}`) que sirve la imagen procesada.

### üîå Endpoints expuestos

- `POST /upload`: Recibe una imagen original desde el usuario.
- `GET /result/{image_id}`: Devuelve la imagen ya procesada.

### üîÅ Comunicaci√≥n

- **RabbitMQ**: se usa como cola de trabajo. Cada porci√≥n de imagen se publica como un mensaje con metadata (posici√≥n, tama√±o, ID).
- **Redis**: se utiliza para la sincronizaci√≥n. Cada Worker publica en un canal indicando que complet√≥ su tarea. El Backend mantiene un contador por imagen y reconstruye el resultado una vez que llegan todas las partes.

### üê≥ Docker

El servicio est√° contenerizado mediante un **Dockerfile** que define:

- Imagen base: `python:3.10-slim`
- Instalaci√≥n de dependencias v√≠a `requirements.txt`
- Exposici√≥n del puerto 80 para FastAPI (con Uvicorn)

Esto permite su despliegue automatizado dentro del cl√∫ster de Kubernetes, facilitando escalabilidad y portabilidad.

### ‚ò∏Ô∏è Kubernetes

El Backend se despliega como un Deployment dentro de Kubernetes, acompa√±ado de un Service para exponer el puerto internamente al cl√∫ster.  
En producci√≥n, puede ser accesible desde el Frontend v√≠a nombre DNS interno (`http://backend`).

## Worker

El Worker es el componente encargado de aplicar el **filtro de Sobel** a una porci√≥n de la imagen. Este procesamiento es intensivo en CPU, por lo que los Workers se ejecutan en **m√°quinas virtuales externas al cl√∫ster de Kubernetes**, optimizando as√≠ la escalabilidad y rendimiento.

### üß† Funcionamiento

Cada Worker se conecta a **RabbitMQ** y queda a la espera de nuevos mensajes.  
Cuando recibe una tarea, realiza el siguiente proceso:

1. Decodifica la imagen (parte de la original) recibida como base64.
2. Aplica el **filtro de Sobel** en los ejes `x` e `y`, utilizando OpenCV.
3. Convierte el resultado en una imagen binaria (blanco y negro).
4. Codifica la imagen procesada nuevamente en base64.
5. Publica el resultado en **Redis**, en un canal que representa el ID de la imagen.

Este enfoque desacopla totalmente a los Workers del backend, permitiendo que se ejecuten en paralelo y en diferentes entornos.

### üì¶ Detalles t√©cnicos

- **Conexiones**:
  - `RabbitMQ`: escucha una cola llamada `image_queue` (o similar).
  - `Redis`: publica en un canal nombrado con el `image_id` correspondiente.
- **Tecnolog√≠as usadas**:
  - `opencv-python`: para el procesamiento de imagen.
  - `pika`: para conexi√≥n con RabbitMQ.
  - `redis-py`: para la conexi√≥n al servidor Redis.
  - `base64` y `numpy`: para manipulaci√≥n y codificaci√≥n de im√°genes.

### üê≥ Docker

El `worker` est√° contenerizado mediante un `Dockerfile` que incluye:

- Imagen base de Python
- Instalaci√≥n de dependencias desde `requirements.txt`
- Ejecuci√≥n del archivo `worker.py` al iniciar el contenedor

### ‚òÅÔ∏è Despliegue en VMs

En lugar de desplegar los Workers dentro del cl√∫ster de Kubernetes, se utilizan **m√°quinas virtuales** externas (provisionadas con Terraform) que permiten:

- Asignar m√°s CPU y memoria espec√≠ficamente para procesamiento.
- Escalar horizontalmente seg√∫n demanda, sin saturar el cl√∫ster principal.

Este dise√±o cumple el objetivo de delegar el procesamiento pesado fuera del entorno orquestado, manteniendo alta eficiencia y paralelismo.

## Frontend

El Frontend es la interfaz mediante la cual el usuario interact√∫a con la plataforma.  
Su funci√≥n principal es permitir la **subida de im√°genes** y mostrar los **resultados procesados** luego de aplicar el filtro de Sobel.

### üß± Componentes

- `index.html`: contiene un formulario simple para subir una imagen v√≠a `POST`, y una secci√≥n que muestra la imagen procesada una vez disponible.
- `nginx.conf`: configuraci√≥n del servidor web que expone el frontend. Redirige internamente los pedidos hacia el Backend cuando es necesario.
- `Dockerfile`: imagen de Nginx que sirve los archivos est√°ticos (HTML) y la configuraci√≥n personalizada.

### üîå Flujo

1. El usuario accede a la interfaz web.
2. Selecciona una imagen y la sube a trav√©s del formulario.
3. La imagen se env√≠a al endpoint `/upload` del Backend.
4. El Frontend consulta peri√≥dicamente si el resultado est√° disponible en `/result/{image_id}`.
5. Una vez listo, se muestra autom√°ticamente la imagen procesada al usuario.

### üê≥ Docker

El Frontend est√° contenerizado usando una imagen base de **Nginx**, con la configuraci√≥n y HTML copiados al directorio correcto:

- Se expone el puerto 80.
- Se utiliza una configuraci√≥n custom (`nginx.conf`) para enrutar correctamente las peticiones hacia el Backend.

### ‚ò∏Ô∏è Kubernetes

El despliegue incluye:

- Un `Deployment` con una √∫nica r√©plica, dado que el tr√°fico esperado es bajo.
- Un `Service` interno para exponer el puerto 80 dentro del cl√∫ster.
- Puede conectarse al Backend por nombre DNS interno (`backend`).

Este dise√±o asegura un frontend liviano, desacoplado, f√°cilmente reemplazable o escalable si se requiere.

## Comunicacion Distribuida: RabbitMQ y Redis

Para coordinar el procesamiento distribuido de im√°genes, el sistema se apoya en dos tecnolog√≠as de mensajer√≠a asincr√≥nica:

- **RabbitMQ**: se utiliza como sistema de colas para distribuir las tareas entre los workers.
- **Redis (Pub/Sub)**: se usa para notificar al backend cuando cada worker termina su parte, permitiendo saber cu√°ndo reconstruir la imagen final.

---

### üì® RabbitMQ ‚Äì Sistema de Colas

RabbitMQ permite desacoplar el env√≠o de tareas del procesamiento.

- En el **Backend**:
  - Se establece una conexi√≥n con RabbitMQ y se publica un mensaje por cada fragmento de imagen generado.
  - Cada mensaje incluye:
    - Un ID global de imagen
    - El √≠ndice del fragmento
    - El total de fragmentos esperados
    - La imagen en base64

- En el **Worker**:
  - Se suscribe a una cola (por defecto: `image_queue`).
  - Cada vez que recibe un mensaje, procesa la imagen y luego publica el resultado en Redis.

Esta arquitectura permite que m√∫ltiples workers procesen tareas de forma paralela, sin necesidad de conocer el origen de la solicitud.

---

### üì¢ Redis ‚Äì Sistema de Notificaci√≥n (Pub/Sub)

Redis se usa como mecanismo ligero de notificaci√≥n:

- Cada **Worker**, al finalizar su tarea, publica el fragmento procesado en un canal Redis identificado por el ID de la imagen (`image_id`).
- El **Backend** mantiene una suscripci√≥n activa al canal de esa imagen.
- Cada vez que recibe un fragmento:
  - Lo almacena en un diccionario temporal.
  - Cuando se reciben todos los fragmentos, los une y guarda el resultado.

Este enfoque elimina la necesidad de polling y garantiza reactividad inmediata ante la finalizaci√≥n de los procesos.

---

### üîÅ Ventajas del esquema RabbitMQ + Redis

- üîÑ **Asincronismo** completo entre partes.
- ‚öñÔ∏è **Balanceo autom√°tico de carga** entre Workers.
- üöÄ **Escalabilidad horizontal** sin afectar al Backend.
- üîî **Notificaci√≥n inmediata** de tareas completadas.

Este esquema de comunicaci√≥n distribuida permite que el sistema escale con eficiencia y mantenga baja latencia en entornos de alta concurrencia.

## Contenerizaci√≥n de Servicios con Docker

Todos los componentes del sistema (Backend, Frontend y Workers) est√°n **empaquetados en contenedores Docker**, lo que facilita su despliegue, escalabilidad y portabilidad.

Cada servicio posee su propio `Dockerfile`, adaptado a sus necesidades espec√≠ficas.

---

### üõ† Backend

- **Imagen base**: `python:3.10-slim`
- **Acciones principales**:
  - Copiar el c√≥digo fuente y `requirements.txt` al contenedor.
  - Instalar las dependencias de Python.
  - Ejecutar el servidor FastAPI usando Uvicorn en el puerto 80.

- **Exposici√≥n**: expone el puerto `80` para comunicaci√≥n interna en Kubernetes.

Este dise√±o liviano asegura un backend r√°pido de inicializar y de bajo consumo de recursos.

---

### ‚öôÔ∏è Worker

- **Imagen base**: `python:3.10-slim`
- **Acciones principales**:
  - Copiar el archivo `worker.py` y su `requirements.txt`.
  - Instalar librer√≠as necesarias como OpenCV, Pika (RabbitMQ) y Redis.
  - Ejecutar el script `worker.py` al inicio del contenedor.

Aunque el Worker est√° preparado para ser contenerizado, en este proyecto se despliega sobre **m√°quinas virtuales externas**, no dentro del cl√∫ster Kubernetes.

---

### üåê Frontend

- **Imagen base**: `nginx:latest`
- **Acciones principales**:
  - Copiar el archivo `index.html` y configuraci√≥n `nginx.conf` personalizada.
  - Servir archivos est√°ticos HTML y manejar la redirecci√≥n de peticiones al Backend.

- **Exposici√≥n**: puerto `80` en Kubernetes.

El uso de Nginx proporciona alta eficiencia para servir contenidos est√°ticos y realizar configuraciones de proxy inverso si fueran necesarias.

---

### üöÄ Ventajas de la contenerizaci√≥n

- üì¶ **Portabilidad**: cada servicio puede ejecutarse en cualquier infraestructura que soporte Docker.
- üîÅ **Reproducibilidad**: los ambientes de desarrollo, prueba y producci√≥n son consistentes.
- ‚ò∏Ô∏è **Compatibilidad nativa** con Kubernetes para orquestaci√≥n y escalado.

La contenerizaci√≥n fue clave para lograr un despliegue r√°pido, modular y altamente escalable del sistema.

## ‚ò∏Ô∏è Orquestaci√≥n con Kubernetes

La plataforma utiliza **Kubernetes** (GKE) como sistema de orquestaci√≥n de contenedores, permitiendo administrar el ciclo de vida de las aplicaciones de forma autom√°tica y escalable.

Se definen distintos componentes Kubernetes para desplegar y gestionar cada servicio:

---

### üì¶ Deployments

Los `Deployment` garantizan que siempre haya una cantidad deseada de pods ejecut√°ndose.

- `backend-deployment.yaml`: despliega el servicio backend (FastAPI).
- `frontend-deployment.yaml`: despliega el servicio frontend (Nginx).
- `worker-deployment.yaml`: despliega el servicio Worker (aunque en este caso se usa principalmente para pruebas, ya que los workers reales corren en VMs externas).
- `rabbitmq-deployment.yaml`: despliega el servicio de colas RabbitMQ.
- `redis-deployment.yaml`: despliega el servicio de base de datos en memoria Redis.
- `nginx-deployment.yaml`: alternativa de despliegue de frontend usando configuraci√≥n personalizada (si aplica).

---

### üåê Services

Los `Service` exponen los Pods para permitir la comunicaci√≥n interna en el cl√∫ster.

- `backend-service.yaml`: Service ClusterIP para que el Frontend pueda alcanzar al Backend.
- `backend-service-external.yaml`: Service LoadBalancer para exponer el Backend al exterior (opcional o en pruebas).
- `frontend-service.yaml`: Service ClusterIP para exponer el Frontend internamente.
- `worker-service.yaml`: (si se desplegaran workers internos).
- `rabbitmq-service.yaml`: expone RabbitMQ para acceso interno.
- `redis-service.yaml`: expone Redis para acceso interno.

---

### üìà Autoscaling (HPA)

Se configura un `HorizontalPodAutoscaler` (`worker-hpa.yaml`) para el `Deployment` de Workers.

- El HPA permite escalar autom√°ticamente la cantidad de pods de Workers en base a la utilizaci√≥n de CPU.
- Esto asegura que el sistema se adapte a cargas variables de procesamiento sin intervenci√≥n manual.

---

### üìã Organizaci√≥n en Node Pools

Siguiendo la consigna del TP:

- Se utilizan **node pools separados** en GKE:
  - Un grupo de nodos para infraestructura (RabbitMQ, Redis).
  - Otro grupo de nodos para las aplicaciones (Frontend, Backend).

Adem√°s, los Workers reales corren sobre m√°quinas virtuales externas al cl√∫ster, manteniendo as√≠ el procesamiento intensivo separado de los servicios b√°sicos.

---

### üöÄ Beneficios de usar Kubernetes

- üìà **Escalabilidad autom√°tica** basada en carga.
- ‚ôªÔ∏è **Alta disponibilidad** mediante replicaci√≥n de pods.
- üîÑ **Actualizaciones seguras** a trav√©s de despliegues rolling.
- üîí **Aislamiento de servicios** usando redes internas del cl√∫ster.

La combinaci√≥n de Kubernetes y GKE permite una plataforma robusta, flexible y lista para producci√≥n.

## Infraestructura como Codigo (IaC) con Terraform

Toda la infraestructura de este proyecto se define utilizando **Terraform**, permitiendo su despliegue autom√°tico, reproducible y versionado.

Terraform se encarga de provisionar:

- El cl√∫ster de Kubernetes en Google Kubernetes Engine (GKE).
- La red de comunicaci√≥n (VPC y subredes).
- Las m√°quinas virtuales externas para el procesamiento intensivo de im√°genes (Workers).

---

### üìã Estructura de Terraform

- `infra/main.tf`: define los recursos principales (VPC, Subnet, GKE Cluster, Node Pools).
- `infra/variables.tf`: variables parametrizadas como proyecto, regi√≥n, zona, etc.
- `infra/outputs.tf`: salidas √∫tiles como la IP del cl√∫ster.
- `infra/terraform.tfvars`: valores espec√≠ficos asignados a las variables.
- `infra/credentials/terraform-admin.json`: credenciales de servicio para autenticaci√≥n en GCP.
- `infra/workers/main.tf`: m√≥dulo independiente que gestiona la creaci√≥n de las VMs externas para Workers.

---

### üõ† Recursos creados

- **VPC propia**: red privada para la comunicaci√≥n segura entre servicios.
- **Subred**: rango de IPs dedicado al cl√∫ster y las VMs.
- **GKE Cluster**:
  - **Node Pool de Infraestructura**: hospeda Redis, RabbitMQ y servicios de soporte.
  - **Node Pool de Aplicaciones**: hospeda Backend, Frontend y servicios de negocio.
- **Instancias de Compute Engine**:
  - VMs espec√≠ficas para ejecutar los Workers fuera del cl√∫ster.

---

### üöÄ Automatizaci√≥n de infraestructura

Mediante simples comandos Terraform:

```bash
cd infra/
terraform init
terraform apply -auto-approve
```

Se levanta toda la infraestructura necesaria para el funcionamiento del sistema. Adem√°s, los m√≥dulos est√°n organizados de manera que se puede destruir (terraform destroy) y reconstruir la infraestructura f√°cilmente en cualquier momento.

## Automatizacion de Despliegue

Para simplificar las tareas de despliegue y ejecuci√≥n del sistema, se implementaron diferentes mecanismos de automatizaci√≥n mediante scripts y archivos auxiliares.

Estos permiten levantar tanto la infraestructura como los servicios de forma r√°pida, consistente y reproducible.

---

### üìú Scripts de automatizaci√≥n

- `deploy_all.ps1`: 
  - Script de PowerShell que automatiza el proceso de despliegue completo:
    - Aplica Terraform para crear la infraestructura.
    - Aplica los manifiestos Kubernetes (`kubectl apply`) para desplegar los servicios.
    - Facilita la puesta en marcha inicial sin intervenci√≥n manual paso a paso.

- `Makefile`:
  - Define comandos √∫tiles para operaciones frecuentes como:
    - Aplicar Terraform (`make infra`)
    - Aplicar manifiestos Kubernetes (`make k8s`)
    - Eliminar recursos (`make destroy`)
    - Otros atajos personalizados.
  - Permite ejecutar procesos con una sola l√≠nea de comando desde terminal.

---

## Pruebas de Rendimiento

Para evaluar el desempe√±o de la plataforma bajo diferentes condiciones de carga, se dise√±aron y ejecutaron pruebas de benchmarking autom√°ticas.

El objetivo fue analizar:

- üìè El impacto del tama√±o de las im√°genes en el tiempo de procesamiento.
- üë• El comportamiento frente a distintos niveles de concurrencia.
- üî• El efecto de la cantidad de workers disponibles en el rendimiento.

---

### üßπ Scripts de prueba

- `test_sender.py`:
  - Script principal de benchmark.
  - Permite enviar m√∫ltiples im√°genes al Backend de forma concurrente.
  - Variables configurables:
    - Tama√±o de la imagen.
    - Nivel de concurrencia (cantidad de hilos simult√°neos).

- `test_benchmark.py`:
  - Extiende las pruebas de `test_sender.py`.
  - Permite ejecutar tests de forma sistem√°tica para m√∫ltiples combinaciones de tama√±os de im√°genes y niveles de concurrencia.
  - Automatiza la recolecci√≥n de resultados para facilitar su posterior an√°lisis.

---

### üìà Recolecci√≥n y An√°lisis de Datos

- Los resultados de las pruebas se guardan en `benchmark_results.csv`.
  - Cada fila incluye:
    - Estado de la respuesta HTTP.
    - Tiempo de procesamiento (elapsed time).
    - Tama√±o de la imagen enviada (en KB).
    - Nivel de concurrencia utilizado.

- `generar_grafico_benchmark.py`:
  - Script que toma el CSV de resultados y genera un gr√°fico de dispersi√≥n (`benchmark_result_plot.png`).
  - El eje X representa el tama√±o de la imagen, y el eje Y el tiempo de procesamiento.
  - Cada color o agrupaci√≥n puede representar diferentes niveles de concurrencia.

---

### üìÑ An√°lisis de Resultados

El an√°lisis detallado se encuentra documentado en `analisis_rendimiento_sobel.md`, incluyendo:

- Comportamiento observado al variar el tama√±o de imagen.
- Impacto de la concurrencia en la latencia.
- Escalabilidad del sistema seg√∫n la cantidad de workers activos.

En general, los resultados muestran:

- Un crecimiento razonablemente lineal del tiempo de procesamiento a medida que aumenta el tama√±o de imagen.
- Beneficios claros de escalar la cantidad de Workers para soportar niveles altos de concurrencia.
- Buen desempe√±o de la plataforma hasta cargas moderadas/altas, con oportunidades de optimizaci√≥n para cargas extremas.

---

### üìä Ejemplo de Gr√°fico de Benchmark

![Gr√°fico de Benchmark](benchmark_result_plot.png)

Este tipo de an√°lisis permite identificar cuellos de botella y validar la capacidad de escalabilidad de la soluci√≥n implementada.


## Resultados y Conclusiones

Las pruebas de rendimiento realizadas permitieron evaluar la plataforma en diferentes condiciones de carga y medir su comportamiento en escenarios realistas.

---

### üß™ Principales resultados observados

- üìè **Tama√±o de la imagen**:
  - El tiempo de procesamiento aumenta de forma proporcional al tama√±o de la imagen enviada.
  - Para im√°genes peque√±as (1KB a 10KB) el tiempo de respuesta es casi inmediato.
  - A partir de tama√±os mayores (1MB o m√°s) se observa una pendiente de crecimiento m√°s marcada en el tiempo de procesamiento.

- üë• **Nivel de concurrencia**:
  - Hasta niveles moderados de concurrencia, el sistema responde de manera eficiente.
  - En cargas altas, sin suficiente cantidad de workers, la latencia comienza a incrementarse significativamente.
  - La incorporaci√≥n de m√°s Workers reduce el tiempo de espera promedio.

- üî• **Cantidad de Workers**:
  - A mayor cantidad de Workers, mejor es el desempe√±o en escenarios de alta concurrencia.
  - La plataforma se beneficia claramente del escalado horizontal de Workers para cargas intensivas.

---

## Health Check y Logs

C√≥mo se manejan los logs.

Health de los servicios (si aplica).

## Escalabilidad

El dise√±o de la plataforma fue pensado para soportar cargas de trabajo variables y adaptarse autom√°ticamente a las necesidades de procesamiento.

La **escalabilidad** se implementa en diferentes niveles:

---

### ‚ò∏Ô∏è Escalabilidad en Kubernetes

- **Horizontal Pod Autoscaler (HPA)**:
  - Se configur√≥ un HPA (`worker-hpa.yaml`) para el `Deployment` de Workers.
  - El HPA ajusta autom√°ticamente la cantidad de Pods de Workers seg√∫n el uso de CPU.
  - Cuando la carga de procesamiento aumenta, Kubernetes lanza nuevos Pods de Worker para mantener la latencia baja.
  - Cuando la carga disminuye, Kubernetes elimina Pods sobrantes para ahorrar recursos.

---

### ‚òÅÔ∏è Escalabilidad de M√°quinas Virtuales Externas

- Los Workers principales corren sobre **m√°quinas virtuales** creadas fuera del cl√∫ster de Kubernetes.
- Esto permite:
  - Asignar m√°s potencia de CPU y RAM espec√≠ficamente para procesamiento intensivo.
  - Agregar o eliminar VMs manualmente (o mediante automatizaci√≥n futura) en funci√≥n de la demanda.
- La arquitectura est√° preparada para escalar el n√∫mero de VMs de forma horizontal, aumentando as√≠ la capacidad total del sistema.



