# ğŸ“‹ README para Hit3

# ğŸ“š Tabla de Contenidos

- [Objetivo General](#objetivo-general)
- [Deploy](#deploy)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [DiseÃ±o de Arquitectura](#diseÃ±o-de-arquitectura)
- [Backend](#backend)
- [Worker](#worker)
- [Frontend](#frontend)
- [Comunicacion Distribuida: RabbitMQ y Redis](#comunicacion-distribuida-rabbitmq-y-redis)
- [Contenerizacion de Servicios con Docker](#contenarizacion-de-servicios-con-docker)
- [Orquestacion con Kubernetes](#ï¸-orquestacion-con-kubernetes)
- [Infraestructura como Codigo (IaC) con Terraform](#ï¸-infraestructura-como-codigo-iac-con-terraform)
- [Automatizacion de Despliegue](#automatizacion-de-despliegue)
- [Pruebas de Rendimiento](#pruebas-de-rendimiento)
- [Resultados y Conclusiones](#resultados-y-conclusiones)
- [Health Check y Logs](#health-check-y-logs)
- [Escalabilidad](#escalabilidad)


## Objetivo General

El presente proyecto tiene como objetivo diseÃ±ar y desplegar una plataforma distribuida para el procesamiento de imÃ¡genes mediante el filtro de Sobel, basada en tecnologÃ­as de contenedores y orquestada en un entorno cloud escalable.

A diferencia de soluciones anteriores de clÃºsteres locales, en este caso se implementa una infraestructura en la nube utilizando Google Kubernetes Engine (GKE) como base, siguiendo las siguientes directrices:

1. Despliegue de clÃºster Kubernetes mediante Terraform, automatizando la provisiÃ³n de:

- Un node pool especÃ­fico para alojar servicios de infraestructura como RabbitMQ (sistema de colas) y Redis (sistema de notificaciones).

- Un node pool destinado a las aplicaciones del sistema: frontend, backend, workers de procesamiento.

2. SeparaciÃ³n de procesamiento intensivo: los procesos de cÃ³mputo pesado (aplicaciÃ³n del filtro Sobel) son ejecutados en mÃ¡quinas virtuales externas al clÃºster de Kubernetes, permitiendo un escalado independiente y optimizado.

3. AutomatizaciÃ³n de despliegues: construcciÃ³n de pipelines que incluyen:

- Pipeline 1: CreaciÃ³n del clÃºster Kubernetes.

- Pipeline 1.1: Despliegue de servicios de infraestructura (RabbitMQ y Redis).

- Pipeline 1.2 - 1.N: Despliegue individual de cada aplicaciÃ³n (frontend, backend, worker).

- Pipeline 2: ProvisiÃ³n de mÃ¡quinas virtuales para workers, buscando escalabilidad dinÃ¡mica.

4. AnÃ¡lisis de desempeÃ±o bajo carga: se realizan pruebas de benchmarking modificando:

- TamaÃ±o de las imÃ¡genes procesadas.

- Nivel de concurrencia de peticiones.

- Cantidad de workers disponibles.

Los resultados obtenidos permiten evaluar la escalabilidad, eficiencia y capacidad de respuesta del sistema ante diferentes condiciones de uso.

## Deploy

Para poder correr el proyecto:

```bash
  make deploy
  .\deploy_all.ps1
```

Para finalizar y liberar recursos:

```bash
  make destroy
```

## Estructura del Repositorio

La estructura de carpetas del proyecto es la siguiente:

```bash

/Hit3/
â”œâ”€â”€ backend/                  # Servicio Backend (FastAPI) que coordina el procesamiento
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                 # Interfaz web del usuario y servidor Nginx
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ nginx.conf
â”‚
â”œâ”€â”€ worker/                   # Servicio Worker que aplica el filtro Sobel
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ worker.py
â”‚
â”œâ”€â”€ infra/                    # Infraestructura como cÃ³digo (Terraform)
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ terraform.tfstate
â”‚   â”œâ”€â”€ .terraform/           # Archivos internos de Terraform
â”‚   â””â”€â”€ workers/              # MÃ³dulo especÃ­fico para mÃ¡quinas de procesamiento externo
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â”œâ”€â”€ terraform.tfvars
â”‚       â””â”€â”€ terraform.tfstate
â”‚
â”œâ”€â”€ k8s_actualizados/         # Manifiestos Kubernetes para despliegue de servicios
â”‚   â”œâ”€â”€ backend-deployment.yaml
â”‚   â”œâ”€â”€ backend-service.yaml
â”‚   â”œâ”€â”€ backend-service-external.yaml
â”‚   â”œâ”€â”€ frontend-deployment.yaml
â”‚   â”œâ”€â”€ frontend-service.yaml
â”‚   â”œâ”€â”€ nginx-deployment.yaml
â”‚   â”œâ”€â”€ nginx-service.yaml
â”‚   â”œâ”€â”€ rabbitmq-deployment.yaml
â”‚   â”œâ”€â”€ rabbitmq-service.yaml
â”‚   â”œâ”€â”€ redis-deployment.yaml
â”‚   â”œâ”€â”€ redis-service.yaml
â”‚   â”œâ”€â”€ worker-deployment.yaml
â”‚   â””â”€â”€ worker-hpa.yaml
â”‚
â”œâ”€â”€ test_images/              # ImÃ¡genes utilizadas para pruebas de benchmarking
â”‚   â”œâ”€â”€ 1024KB.jpg
â”‚   â””â”€â”€ 10240KB.jpg
â”‚
â”œâ”€â”€ analisis_rendimiento_sobel.md   # AnÃ¡lisis del rendimiento obtenido
â”œâ”€â”€ benchmark_results.csv           # Datos de benchmark
â”œâ”€â”€ benchmark_result_plot.png       # GrÃ¡fico con resultados
â”œâ”€â”€ generar_grafico_benchmark.py    # Script para generar el grÃ¡fico
â”œâ”€â”€ deploy_all.ps1                  # Script de despliegue automatizado (PowerShell)
â”œâ”€â”€ Makefile                        # Comandos Ãºtiles de automatizaciÃ³n
â”œâ”€â”€ test_sender.py                  # Script de pruebas de carga
â”œâ”€â”€ test_benchmark.py               # Script de pruebas especÃ­ficas
â”œâ”€â”€ terraform.tfstate               # Estado de Terraform general
â”œâ”€â”€ README.md                       # DocumentaciÃ³n del proyecto
â””â”€â”€ test.jpg                        # Imagen de prueba manual

```

## DiseÃ±o de Arquitectura

El sistema estÃ¡ compuesto por mÃºltiples servicios distribuidos, organizados en una arquitectura asincrÃ³nica y escalable. El flujo principal de procesamiento es el siguiente:

```bash

[ Usuario ]
     |
     v
[ Frontend (Nginx + HTML) ]
     |
     v
[ Backend (FastAPI) ]
     |
     v
[ Divide Imagen + Encola tareas en RabbitMQ ]
     |
     v
[ Workers (en VMs externas) ]
     |
     v
[ Resultado parcial a Redis ]
     |
     v
[ Backend reconstruye imagen ]
     |
     v
[ Frontend muestra resultado final ]

```

Otros componentes del sistema:

- ğŸ” RabbitMQ: cola de tareas de procesamiento.

- ğŸ“¬ Redis: notificaciÃ³n de finalizaciÃ³n mediante Pub/Sub.

- â˜¸ï¸ Kubernetes (GKE): orquesta frontend, backend, Redis y RabbitMQ.

- ğŸ–¥ï¸ VMs externas: ejecutan los workers fuera del clÃºster.


```mermaid
flowchart TD
 subgraph Usuario["Usuario"]
        A1["Usuario en navegador"]
  end
 subgraph Frontend["Nginx"]
        B1["Formulario HTML para subir imagen"]
        B2["Consulta resultado procesado"]
  end
 subgraph Backend["FastAPI"]
        C1["Recibe imagen"]
        C2["Divide imagen en fragmentos"]
        C3["Encola tareas en RabbitMQ"]
        C4["Escucha Redis Pub/Sub"]
        C5["Reconstruye imagen final"]
        C6["Sirve resultado procesado"]
  end
 subgraph RabbitMQ["Cola de mensajes"]
        D1["Cola de tareas de fragmentos"]
  end
 subgraph Workers["VMs Externas"]
        E1["Worker escucha cola"]
        E2["Procesa fragmento - Filtro Sobel"]
        E3["Publica resultado en Redis"]
  end
 subgraph Redis["Pub/Sub"]
        F1["Canal Pub/Sub por imagen"]
  end
 subgraph subGraph6["Kubernetes Cluster"]
        G1["Node Pool Infraestructura"]
        G2["Node Pool Aplicaciones"]
  end
    A1 --> B1
    B1 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> D1
    D1 --> E1
    E1 --> E2
    E2 --> E3
    E3 --> F1
    F1 --> C4
    C4 --> C5
    C5 --> C6
    C6 --> B2
    B2 --> A1
    G1 --> D1 & F1
    G2 --> B1 & C1


```





### Explicacion del Flujo

El flujo de trabajo comienza cuando el usuario sube una imagen a travÃ©s del **Frontend**, una interfaz simple servida por Nginx.  
Esta imagen es enviada al **Backend**, que actÃºa como coordinador central del sistema.

El Backend divide la imagen en partes y encola cada tarea en **RabbitMQ**, permitiendo una distribuciÃ³n asincrÃ³nica del trabajo.  
Las tareas son consumidas por los **Workers**, que se ejecutan en **mÃ¡quinas virtuales externas** al clÃºster de Kubernetes.  
Cada Worker aplica el **filtro de Sobel** a su porciÃ³n asignada.

Una vez finalizado el procesamiento, cada Worker publica su resultado en **Redis** mediante un canal de *Pub/Sub*.  
Cuando el Backend detecta que todas las partes fueron procesadas, reconstruye la imagen completa.

Finalmente, el resultado es reenviado al Frontend, donde el usuario puede visualizar la imagen procesada.

Este diseÃ±o desacopla los componentes, favorece la paralelizaciÃ³n y permite escalar horizontalmente tanto el procesamiento como los servicios.

## Backend

El Backend es el nÃºcleo lÃ³gico del sistema. EstÃ¡ desarrollado en **Python** utilizando el framework **FastAPI**, lo cual permite definir servicios web de forma sencilla, robusta y con gran rendimiento asincrÃ³nico.

### ğŸ¯ Funcionalidad principal

El Backend cumple mÃºltiples roles:

- **RecepciÃ³n de imÃ¡genes** desde el Frontend a travÃ©s de un endpoint HTTP (`/upload`).
- **DivisiÃ³n de la imagen** en partes iguales, segÃºn la cantidad de Workers disponibles.
- **Encolado de tareas** en **RabbitMQ**, enviando un mensaje por cada porciÃ³n de la imagen.
- **Escucha de Redis** por eventos de finalizaciÃ³n, a travÃ©s de **Pub/Sub**, para saber cuÃ¡ndo todos los Workers terminaron.
- **Reensamblado de la imagen final**, uniendo todas las partes procesadas por los Workers.
- **EnvÃ­o del resultado** al Frontend mediante un endpoint (`/result/{image_id}`) que sirve la imagen procesada.

### ğŸ”Œ Endpoints expuestos

- `POST /upload`: Recibe una imagen original desde el usuario.
- `GET /result/{image_id}`: Devuelve la imagen ya procesada.

### ğŸ” ComunicaciÃ³n

- **RabbitMQ**: se usa como cola de trabajo. Cada porciÃ³n de imagen se publica como un mensaje con metadata (posiciÃ³n, tamaÃ±o, ID).
- **Redis**: se utiliza para la sincronizaciÃ³n. Cada Worker publica en un canal indicando que completÃ³ su tarea. El Backend mantiene un contador por imagen y reconstruye el resultado una vez que llegan todas las partes.

### ğŸ³ Docker

El servicio estÃ¡ contenerizado mediante un **Dockerfile** que define:

- Imagen base: `python:3.10-slim`
- InstalaciÃ³n de dependencias vÃ­a `requirements.txt`
- ExposiciÃ³n del puerto 80 para FastAPI (con Uvicorn)

Esto permite su despliegue automatizado dentro del clÃºster de Kubernetes, facilitando escalabilidad y portabilidad.

### â˜¸ï¸ Kubernetes

El Backend se despliega como un Deployment dentro de Kubernetes, acompaÃ±ado de un Service para exponer el puerto internamente al clÃºster.  
En producciÃ³n, puede ser accesible desde el Frontend vÃ­a nombre DNS interno (`http://backend`).

## Worker

El Worker es el componente encargado de aplicar el **filtro de Sobel** a una porciÃ³n de la imagen. Este procesamiento es intensivo en CPU, por lo que los Workers se ejecutan en **mÃ¡quinas virtuales externas al clÃºster de Kubernetes**, optimizando asÃ­ la escalabilidad y rendimiento.

### ğŸ§  Funcionamiento

Cada Worker se conecta a **RabbitMQ** y queda a la espera de nuevos mensajes.  
Cuando recibe una tarea, realiza el siguiente proceso:

1. Decodifica la imagen (parte de la original) recibida como base64.
2. Aplica el **filtro de Sobel** en los ejes `x` e `y`, utilizando OpenCV.
3. Convierte el resultado en una imagen binaria (blanco y negro).
4. Codifica la imagen procesada nuevamente en base64.
5. Publica el resultado en **Redis**, en un canal que representa el ID de la imagen.

Este enfoque desacopla totalmente a los Workers del backend, permitiendo que se ejecuten en paralelo y en diferentes entornos.

### ğŸ“¦ Detalles tÃ©cnicos

- **Conexiones**:
  - `RabbitMQ`: escucha una cola llamada `image_queue` (o similar).
  - `Redis`: publica en un canal nombrado con el `image_id` correspondiente.
- **TecnologÃ­as usadas**:
  - `opencv-python`: para el procesamiento de imagen.
  - `pika`: para conexiÃ³n con RabbitMQ.
  - `redis-py`: para la conexiÃ³n al servidor Redis.
  - `base64` y `numpy`: para manipulaciÃ³n y codificaciÃ³n de imÃ¡genes.

### ğŸ³ Docker

El `worker` estÃ¡ contenerizado mediante un `Dockerfile` que incluye:

- Imagen base de Python
- InstalaciÃ³n de dependencias desde `requirements.txt`
- EjecuciÃ³n del archivo `worker.py` al iniciar el contenedor

### â˜ï¸ Despliegue en VMs

En lugar de desplegar los Workers dentro del clÃºster de Kubernetes, se utilizan **mÃ¡quinas virtuales** externas (provisionadas con Terraform) que permiten:

- Asignar mÃ¡s CPU y memoria especÃ­ficamente para procesamiento.
- Escalar horizontalmente segÃºn demanda, sin saturar el clÃºster principal.

Este diseÃ±o cumple el objetivo de delegar el procesamiento pesado fuera del entorno orquestado, manteniendo alta eficiencia y paralelismo.

## Frontend

El Frontend es la interfaz mediante la cual el usuario interactÃºa con la plataforma.  
Su funciÃ³n principal es permitir la **subida de imÃ¡genes** y mostrar los **resultados procesados** luego de aplicar el filtro de Sobel.

### ğŸ§± Componentes

- `index.html`: contiene un formulario simple para subir una imagen vÃ­a `POST`, y una secciÃ³n que muestra la imagen procesada una vez disponible.
- `nginx.conf`: configuraciÃ³n del servidor web que expone el frontend. Redirige internamente los pedidos hacia el Backend cuando es necesario.
- `Dockerfile`: imagen de Nginx que sirve los archivos estÃ¡ticos (HTML) y la configuraciÃ³n personalizada.

### ğŸ”Œ Flujo

1. El usuario accede a la interfaz web.
2. Selecciona una imagen y la sube a travÃ©s del formulario.
3. La imagen se envÃ­a al endpoint `/upload` del Backend.
4. El Frontend consulta periÃ³dicamente si el resultado estÃ¡ disponible en `/result/{image_id}`.
5. Una vez listo, se muestra automÃ¡ticamente la imagen procesada al usuario.

### ğŸ³ Docker

El Frontend estÃ¡ contenerizado usando una imagen base de **Nginx**, con la configuraciÃ³n y HTML copiados al directorio correcto:

- Se expone el puerto 80.
- Se utiliza una configuraciÃ³n custom (`nginx.conf`) para enrutar correctamente las peticiones hacia el Backend.

### â˜¸ï¸ Kubernetes

El despliegue incluye:

- Un `Deployment` con una Ãºnica rÃ©plica, dado que el trÃ¡fico esperado es bajo.
- Un `Service` interno para exponer el puerto 80 dentro del clÃºster.
- Puede conectarse al Backend por nombre DNS interno (`backend`).

Este diseÃ±o asegura un frontend liviano, desacoplado, fÃ¡cilmente reemplazable o escalable si se requiere.

## Comunicacion Distribuida: RabbitMQ y Redis

Para coordinar el procesamiento distribuido de imÃ¡genes, el sistema se apoya en dos tecnologÃ­as de mensajerÃ­a asincrÃ³nica:

- **RabbitMQ**: se utiliza como sistema de colas para distribuir las tareas entre los workers.
- **Redis (Pub/Sub)**: se usa para notificar al backend cuando cada worker termina su parte, permitiendo saber cuÃ¡ndo reconstruir la imagen final.

---

### ğŸ“¨ RabbitMQ â€“ Sistema de Colas

RabbitMQ permite desacoplar el envÃ­o de tareas del procesamiento.

- En el **Backend**:
  - Se establece una conexiÃ³n con RabbitMQ y se publica un mensaje por cada fragmento de imagen generado.
  - Cada mensaje incluye:
    - Un ID global de imagen
    - El Ã­ndice del fragmento
    - El total de fragmentos esperados
    - La imagen en base64

- En el **Worker**:
  - Se suscribe a una cola (por defecto: `image_queue`).
  - Cada vez que recibe un mensaje, procesa la imagen y luego publica el resultado en Redis.

Esta arquitectura permite que mÃºltiples workers procesen tareas de forma paralela, sin necesidad de conocer el origen de la solicitud.

---

### ğŸ“¢ Redis â€“ Sistema de NotificaciÃ³n (Pub/Sub)

Redis se usa como mecanismo ligero de notificaciÃ³n:

- Cada **Worker**, al finalizar su tarea, publica el fragmento procesado en un canal Redis identificado por el ID de la imagen (`image_id`).
- El **Backend** mantiene una suscripciÃ³n activa al canal de esa imagen.
- Cada vez que recibe un fragmento:
  - Lo almacena en un diccionario temporal.
  - Cuando se reciben todos los fragmentos, los une y guarda el resultado.

Este enfoque elimina la necesidad de polling y garantiza reactividad inmediata ante la finalizaciÃ³n de los procesos.

---

### ğŸ” Ventajas del esquema RabbitMQ + Redis

- ğŸ”„ **Asincronismo** completo entre partes.
- âš–ï¸ **Balanceo automÃ¡tico de carga** entre Workers.
- ğŸš€ **Escalabilidad horizontal** sin afectar al Backend.
- ğŸ”” **NotificaciÃ³n inmediata** de tareas completadas.

Este esquema de comunicaciÃ³n distribuida permite que el sistema escale con eficiencia y mantenga baja latencia en entornos de alta concurrencia.

## ContenerizaciÃ³n de Servicios con Docker

Todos los componentes del sistema (Backend, Frontend y Workers) estÃ¡n **empaquetados en contenedores Docker**, lo que facilita su despliegue, escalabilidad y portabilidad.

Cada servicio posee su propio `Dockerfile`, adaptado a sus necesidades especÃ­ficas.

---

### ğŸ›  Backend

- **Imagen base**: `python:3.10-slim`
- **Acciones principales**:
  - Copiar el cÃ³digo fuente y `requirements.txt` al contenedor.
  - Instalar las dependencias de Python.
  - Ejecutar el servidor FastAPI usando Uvicorn en el puerto 80.

- **ExposiciÃ³n**: expone el puerto `80` para comunicaciÃ³n interna en Kubernetes.

Este diseÃ±o liviano asegura un backend rÃ¡pido de inicializar y de bajo consumo de recursos.

---

### âš™ï¸ Worker

- **Imagen base**: `python:3.10-slim`
- **Acciones principales**:
  - Copiar el archivo `worker.py` y su `requirements.txt`.
  - Instalar librerÃ­as necesarias como OpenCV, Pika (RabbitMQ) y Redis.
  - Ejecutar el script `worker.py` al inicio del contenedor.

Aunque el Worker estÃ¡ preparado para ser contenerizado, en este proyecto se despliega sobre **mÃ¡quinas virtuales externas**, no dentro del clÃºster Kubernetes.

---

### ğŸŒ Frontend

- **Imagen base**: `nginx:latest`
- **Acciones principales**:
  - Copiar el archivo `index.html` y configuraciÃ³n `nginx.conf` personalizada.
  - Servir archivos estÃ¡ticos HTML y manejar la redirecciÃ³n de peticiones al Backend.

- **ExposiciÃ³n**: puerto `80` en Kubernetes.

El uso de Nginx proporciona alta eficiencia para servir contenidos estÃ¡ticos y realizar configuraciones de proxy inverso si fueran necesarias.

---

### ğŸš€ Ventajas de la contenerizaciÃ³n

- ğŸ“¦ **Portabilidad**: cada servicio puede ejecutarse en cualquier infraestructura que soporte Docker.
- ğŸ” **Reproducibilidad**: los ambientes de desarrollo, prueba y producciÃ³n son consistentes.
- â˜¸ï¸ **Compatibilidad nativa** con Kubernetes para orquestaciÃ³n y escalado.

La contenerizaciÃ³n fue clave para lograr un despliegue rÃ¡pido, modular y altamente escalable del sistema.

## â˜¸ï¸ OrquestaciÃ³n con Kubernetes

La plataforma utiliza **Kubernetes** (GKE) como sistema de orquestaciÃ³n de contenedores, permitiendo administrar el ciclo de vida de las aplicaciones de forma automÃ¡tica y escalable.

Se definen distintos componentes Kubernetes para desplegar y gestionar cada servicio:

---

### ğŸ“¦ Deployments

Los `Deployment` garantizan que siempre haya una cantidad deseada de pods ejecutÃ¡ndose.

- `backend-deployment.yaml`: despliega el servicio backend (FastAPI).
- `frontend-deployment.yaml`: despliega el servicio frontend (Nginx).
- `worker-deployment.yaml`: despliega el servicio Worker (aunque en este caso se usa principalmente para pruebas, ya que los workers reales corren en VMs externas).
- `rabbitmq-deployment.yaml`: despliega el servicio de colas RabbitMQ.
- `redis-deployment.yaml`: despliega el servicio de base de datos en memoria Redis.
- `nginx-deployment.yaml`: alternativa de despliegue de frontend usando configuraciÃ³n personalizada (si aplica).

---

### ğŸŒ Services

Los `Service` exponen los Pods para permitir la comunicaciÃ³n interna en el clÃºster.

- `backend-service.yaml`: Service ClusterIP para que el Frontend pueda alcanzar al Backend.
- `backend-service-external.yaml`: Service LoadBalancer para exponer el Backend al exterior (opcional o en pruebas).
- `frontend-service.yaml`: Service ClusterIP para exponer el Frontend internamente.
- `worker-service.yaml`: (si se desplegaran workers internos).
- `rabbitmq-service.yaml`: expone RabbitMQ para acceso interno.
- `redis-service.yaml`: expone Redis para acceso interno.

---

### ğŸ“ˆ Autoscaling (HPA)

Se configura un `HorizontalPodAutoscaler` (`worker-hpa.yaml`) para el `Deployment` de Workers.

- El HPA permite escalar automÃ¡ticamente la cantidad de pods de Workers en base a la utilizaciÃ³n de CPU.
- Esto asegura que el sistema se adapte a cargas variables de procesamiento sin intervenciÃ³n manual.

---

### ğŸ“‹ OrganizaciÃ³n en Node Pools

Siguiendo la consigna del TP:

- Se utilizan **node pools separados** en GKE:
  - Un grupo de nodos para infraestructura (RabbitMQ, Redis).
  - Otro grupo de nodos para las aplicaciones (Frontend, Backend).

AdemÃ¡s, los Workers reales corren sobre mÃ¡quinas virtuales externas al clÃºster, manteniendo asÃ­ el procesamiento intensivo separado de los servicios bÃ¡sicos.

---

### ğŸš€ Beneficios de usar Kubernetes

- ğŸ“ˆ **Escalabilidad automÃ¡tica** basada en carga.
- â™»ï¸ **Alta disponibilidad** mediante replicaciÃ³n de pods.
- ğŸ”„ **Actualizaciones seguras** a travÃ©s de despliegues rolling.
- ğŸ”’ **Aislamiento de servicios** usando redes internas del clÃºster.

La combinaciÃ³n de Kubernetes y GKE permite una plataforma robusta, flexible y lista para producciÃ³n.

## Infraestructura como Codigo (IaC) con Terraform

Toda la infraestructura de este proyecto se define utilizando **Terraform**, permitiendo su despliegue automÃ¡tico, reproducible y versionado.

Terraform se encarga de provisionar:

- El clÃºster de Kubernetes en Google Kubernetes Engine (GKE).
- La red de comunicaciÃ³n (VPC y subredes).
- Las mÃ¡quinas virtuales externas para el procesamiento intensivo de imÃ¡genes (Workers).

---

### ğŸ“‹ Estructura de Terraform

- `infra/main.tf`: define los recursos principales (VPC, Subnet, GKE Cluster, Node Pools).
- `infra/variables.tf`: variables parametrizadas como proyecto, regiÃ³n, zona, etc.
- `infra/outputs.tf`: salidas Ãºtiles como la IP del clÃºster.
- `infra/terraform.tfvars`: valores especÃ­ficos asignados a las variables.
- `infra/credentials/terraform-admin.json`: credenciales de servicio para autenticaciÃ³n en GCP.
- `infra/workers/main.tf`: mÃ³dulo independiente que gestiona la creaciÃ³n de las VMs externas para Workers.

---

### ğŸ›  Recursos creados

- **VPC propia**: red privada para la comunicaciÃ³n segura entre servicios.
- **Subred**: rango de IPs dedicado al clÃºster y las VMs.
- **GKE Cluster**:
  - **Node Pool de Infraestructura**: hospeda Redis, RabbitMQ y servicios de soporte.
  - **Node Pool de Aplicaciones**: hospeda Backend, Frontend y servicios de negocio.
- **Instancias de Compute Engine**:
  - VMs especÃ­ficas para ejecutar los Workers fuera del clÃºster.

---

### ğŸš€ AutomatizaciÃ³n de infraestructura

Mediante simples comandos Terraform:

```bash
cd infra/
terraform init
terraform apply -auto-approve
```

Se levanta toda la infraestructura necesaria para el funcionamiento del sistema. AdemÃ¡s, los mÃ³dulos estÃ¡n organizados de manera que se puede destruir (terraform destroy) y reconstruir la infraestructura fÃ¡cilmente en cualquier momento.

## Automatizacion de Despliegue

Para simplificar las tareas de despliegue y ejecuciÃ³n del sistema, se implementaron diferentes mecanismos de automatizaciÃ³n mediante scripts y archivos auxiliares.

Estos permiten levantar tanto la infraestructura como los servicios de forma rÃ¡pida, consistente y reproducible.

---

### ğŸ“œ Scripts de automatizaciÃ³n

- `deploy_all.ps1`: 
  - Script de PowerShell que automatiza el proceso de despliegue completo:
    - Aplica Terraform para crear la infraestructura.
    - Aplica los manifiestos Kubernetes (`kubectl apply`) para desplegar los servicios.
    - Facilita la puesta en marcha inicial sin intervenciÃ³n manual paso a paso.

- `Makefile`:
  - Define comandos Ãºtiles para operaciones frecuentes como:
    - Aplicar Terraform (`make infra`)
    - Aplicar manifiestos Kubernetes (`make k8s`)
    - Eliminar recursos (`make destroy`)
    - Otros atajos personalizados.
  - Permite ejecutar procesos con una sola lÃ­nea de comando desde terminal.

---

## Pruebas de Rendimiento

Para evaluar el desempeÃ±o de la plataforma bajo diferentes condiciones de carga, se diseÃ±aron y ejecutaron pruebas de benchmarking automÃ¡ticas.

El objetivo fue analizar:

- ğŸ“ El impacto del tamaÃ±o de las imÃ¡genes en el tiempo de procesamiento.
- ğŸ‘¥ El comportamiento frente a distintos niveles de concurrencia.
- ğŸ”¥ El efecto de la cantidad de workers disponibles en el rendimiento.

---

### ğŸ§¹ Scripts de prueba

- `test_sender.py`:
  - Script principal de benchmark.
  - Permite enviar mÃºltiples imÃ¡genes al Backend de forma concurrente.
  - Variables configurables:
    - TamaÃ±o de la imagen.
    - Nivel de concurrencia (cantidad de hilos simultÃ¡neos).

- `test_benchmark.py`:
  - Extiende las pruebas de `test_sender.py`.
  - Permite ejecutar tests de forma sistemÃ¡tica para mÃºltiples combinaciones de tamaÃ±os de imÃ¡genes y niveles de concurrencia.
  - Automatiza la recolecciÃ³n de resultados para facilitar su posterior anÃ¡lisis.

---

### ğŸ“ˆ RecolecciÃ³n y AnÃ¡lisis de Datos

- Los resultados de las pruebas se guardan en `benchmark_results.csv`.
  - Cada fila incluye:
    - Estado de la respuesta HTTP.
    - Tiempo de procesamiento (elapsed time).
    - TamaÃ±o de la imagen enviada (en KB).
    - Nivel de concurrencia utilizado.

- `generar_grafico_benchmark.py`:
  - Script que toma el CSV de resultados y genera un grÃ¡fico de dispersiÃ³n (`benchmark_result_plot.png`).
  - El eje X representa el tamaÃ±o de la imagen, y el eje Y el tiempo de procesamiento.
  - Cada color o agrupaciÃ³n puede representar diferentes niveles de concurrencia.

---

### ğŸ“„ AnÃ¡lisis de Resultados

El anÃ¡lisis detallado se encuentra documentado en `analisis_rendimiento_sobel.md`, incluyendo:

- Comportamiento observado al variar el tamaÃ±o de imagen.
- Impacto de la concurrencia en la latencia.
- Escalabilidad del sistema segÃºn la cantidad de workers activos.

En general, los resultados muestran:

- Un crecimiento razonablemente lineal del tiempo de procesamiento a medida que aumenta el tamaÃ±o de imagen.
- Beneficios claros de escalar la cantidad de Workers para soportar niveles altos de concurrencia.
- Buen desempeÃ±o de la plataforma hasta cargas moderadas/altas, con oportunidades de optimizaciÃ³n para cargas extremas.

---

### ğŸ“Š Ejemplo de GrÃ¡fico de Benchmark

![GrÃ¡fico de Benchmark](benchmark_result_plot.png)

Este tipo de anÃ¡lisis permite identificar cuellos de botella y validar la capacidad de escalabilidad de la soluciÃ³n implementada.


## Resultados y Conclusiones

Las pruebas de rendimiento realizadas permitieron evaluar la plataforma en diferentes condiciones de carga y medir su comportamiento en escenarios realistas.

---

### ğŸ§ª Principales resultados observados

- ğŸ“ **TamaÃ±o de la imagen**:
  - El tiempo de procesamiento aumenta de forma proporcional al tamaÃ±o de la imagen enviada.
  - Para imÃ¡genes pequeÃ±as (1KB a 10KB) el tiempo de respuesta es casi inmediato.
  - A partir de tamaÃ±os mayores (1MB o mÃ¡s) se observa una pendiente de crecimiento mÃ¡s marcada en el tiempo de procesamiento.

- ğŸ‘¥ **Nivel de concurrencia**:
  - Hasta niveles moderados de concurrencia, el sistema responde de manera eficiente.
  - En cargas altas, sin suficiente cantidad de workers, la latencia comienza a incrementarse significativamente.
  - La incorporaciÃ³n de mÃ¡s Workers reduce el tiempo de espera promedio.

- ğŸ”¥ **Cantidad de Workers**:
  - A mayor cantidad de Workers, mejor es el desempeÃ±o en escenarios de alta concurrencia.
  - La plataforma se beneficia claramente del escalado horizontal de Workers para cargas intensivas.

---

## Health Check y Logs

CÃ³mo se manejan los logs.

Health de los servicios (si aplica).

## Escalabilidad

El diseÃ±o de la plataforma fue pensado para soportar cargas de trabajo variables y adaptarse automÃ¡ticamente a las necesidades de procesamiento.

La **escalabilidad** se implementa en diferentes niveles:

---

### â˜¸ï¸ Escalabilidad en Kubernetes

- **Horizontal Pod Autoscaler (HPA)**:
  - Se configurÃ³ un HPA (`worker-hpa.yaml`) para el `Deployment` de Workers.
  - El HPA ajusta automÃ¡ticamente la cantidad de Pods de Workers segÃºn el uso de CPU.
  - Cuando la carga de procesamiento aumenta, Kubernetes lanza nuevos Pods de Worker para mantener la latencia baja.
  - Cuando la carga disminuye, Kubernetes elimina Pods sobrantes para ahorrar recursos.

---

### â˜ï¸ Escalabilidad de MÃ¡quinas Virtuales Externas

- Los Workers principales corren sobre **mÃ¡quinas virtuales** creadas fuera del clÃºster de Kubernetes.
- Esto permite:
  - Asignar mÃ¡s potencia de CPU y RAM especÃ­ficamente para procesamiento intensivo.
  - Agregar o eliminar VMs manualmente (o mediante automatizaciÃ³n futura) en funciÃ³n de la demanda.
- La arquitectura estÃ¡ preparada para escalar el nÃºmero de VMs de forma horizontal, aumentando asÃ­ la capacidad total del sistema.



