
# Informe sobre el repositorio NVIDIA/cccl (CUDA Core Compute Libraries)

El repositorio **NVIDIA/cccl** en GitHub es b√°sicamente una caja de herramientas para desarrolladores que laburan con CUDA en C++. En criollo, es un conjunto de librer√≠as que te facilita escribir c√≥digo eficiente y seguro para correr en GPUs de NVIDIA.

Lo interesante es que este repo junta tres librer√≠as que antes viv√≠an por separado:

‚úÖ **Thrust** ‚Üí Es como el ‚ÄúSTL paralelo‚Äù de CUDA. Tiene algoritmos paralelos de alto nivel que te permiten laburar en GPU o CPU sin romperte mucho la cabeza.

‚úÖ **CUB** ‚Üí Es m√°s bajo nivel, pensado para sacarle el jugo a CUDA al m√°ximo. Tiene algoritmos tipo reducci√≥n, escaneo, etc., para kernels personalizados.

‚úÖ **libcudacxx** ‚Üí Es la implementaci√≥n de la Standard Library de C++ adaptada a CUDA. Trae cosas como atomics, control de cach√©, sincronizaci√≥n, etc., para el c√≥digo que corre en GPU.

El objetivo de juntar todo en este repo es simplificarle la vida a los devs: ahora tienen todo lo esencial para CUDA C++ en un solo lugar, con una versi√≥n unificada, menos problemas de compatibilidad y m√°s facilidad para mantenerse al d√≠a.

## ¬øCu√°ndo se actualiz√≥ por √∫ltima vez?

El repo est√° muy activo todo el tiempo, tiene m√°s de **11.000 commits**, **188 branches** y **35 tags** . Eso habla de una comunidad activa y un equipo de desarrollo detr√°s que no para.

## Otros detalles

- Es **header-only** ‚Üí no ten√©s que andar compilando librer√≠as aparte, solo incluir los headers y listo.
- Es compatible con **CMake** y tiene paquetes para **Conda**, as√≠ que integrarlo a proyectos existentes es bastante sencillo.
- Lo pod√©s usar con CUDA Toolkit, pero si quer√©s lo m√°s nuevo, pod√©s tirar directamente del repo en GitHub.
- Tiene ejemplos de uso, como una reducci√≥n paralela usando Thrust, CUB y libcudacxx, para que puedas comparar qu√© onda cada uno.

# Informe sobre Thrust (The C++ Parallel Algorithms Library)

**Thrust** es una librer√≠a C++ de algoritmos paralelos que jug√≥ un rol clave en la llegada de algoritmos paralelos al est√°ndar de C++. B√°sicamente, te permite escribir c√≥digo paralelo para GPUs y CPUs de forma sencilla y portable, usando interfaces de alto nivel al estilo STL (Standard Template Library).

Con Thrust, pod√©s aprovechar la potencia de CUDA, TBB (Threading Building Blocks) y OpenMP sin tener que lidiar con los detalles bajos como manejo de memoria y sincronizaci√≥n. Esto mejora la productividad del programador, porque te pod√©s concentrar en el algoritmo en vez de pelearte con la infraestructura.

## Caracter√≠sticas principales

- Interfaces similares a STL con plantillas (templated) para algoritmos paralelos.
- Funciona sobre GPUs (CUDA) y CPUs multicore (TBB, OpenMP).
- Viene incluido en el CUDA Toolkit y en el NVIDIA HPC SDK, as√≠ que si ya ten√©s alguno de esos, no necesit√°s instalar nada extra.
- Es open source, disponible en GitHub.

## Rendimiento

Thrust permite aceleraciones considerables frente a CPU multicore: por ejemplo, el algoritmo `thrust::sort` puede ser entre 5x y 100x m√°s r√°pido que el STL o TBB.

## Estado actual

Desde marzo de 2024, Thrust forma parte de CUDA Core Compute Libraries (CCCL), as√≠ que toda la gesti√≥n de versiones, issues y mejoras ahora pasa por ese repositorio unificado.

# Informe de Ejecuci√≥n - Thrust Example (CUDA)

## Consigna

Compile y ejecute el primer ejemplo que se le presenta en  
https://docs.nvidia.com/cuda/thrust/index.html#vectors

> **Pregunta gu√≠a:**  
¬øNecesito instalar algo adicional o ya estaba disponible con CUDA?

---

## Resumen del proceso

El objetivo era compilar y ejecutar este c√≥digo de ejemplo usando `nvcc`:

```cpp
#include <thrust/host_vector.h>
#include <thrust/device_vector.h>
#include <thrust/generate.h>
#include <thrust/sort.h>
#include <thrust/copy.h>
#include <thrust/random.h>

int main() {
    thrust::default_random_engine rng(1337);
    thrust::uniform_int_distribution<int> dist;
    thrust::host_vector<int> h_vec(32 << 20);
    thrust::generate(h_vec.begin(), h_vec.end(), [&] { return dist(rng); });

    thrust::device_vector<int> d_vec = h_vec;
    thrust::sort(d_vec.begin(), d_vec.end());
    thrust::copy(d_vec.begin(), d_vec.end(), h_vec.begin());
}
```

---

## ¬øQu√© es Thrust y para qu√© sirve?

El programa de ejemplo no es un simple `printf("Hola GPU")` como en el cl√°sico "Hola Mundo",  
sino que utiliza **Thrust**, una biblioteca de plantillas C++ incluida en CUDA Toolkit.

### ‚úÖ ¬øQu√© es Thrust?

Thrust es una biblioteca de algoritmos paralelos en C++ que proporciona:
- Vectores en CPU (`thrust::host_vector`) y GPU (`thrust::device_vector`),
- Algoritmos paralelos como `sort`, `reduce`, `transform`, `generate`,
- Una interfaz de alto nivel similar a la STL de C++,
- Optimizaci√≥n autom√°tica en CUDA para GPUs.

### ‚úÖ ¬øPor qu√© lo necesitaste para este ejemplo?

Este programa usa:
- `thrust::host_vector` ‚Üí para almacenar datos en el host (CPU),
- `thrust::device_vector` ‚Üí para operar en el dispositivo (GPU),
- `thrust::generate`, `thrust::sort`, `thrust::copy` ‚Üí para generar, ordenar y copiar datos.

A diferencia de un kernel `__global__` simple como en ‚ÄúHola Mundo‚Äù,  
este ejemplo requiere:
- Tener **Thrust disponible** (viene con CUDA Toolkit),
- Que el compilador entienda las plantillas C++ usadas en Thrust,
- Que la GPU soporte las arquitecturas CUDA necesarias.

### ‚úÖ ¬øQu√© es lo nuevo respecto a Hola Mundo?

- Usa librer√≠as C++ avanzadas (`<thrust/*>`),
- Necesita un compilador C++ que soporte plantillas modernas,
- Hace operaciones reales en GPU (no solo imprime texto),
- Depende de compatibilidad entre Toolkit, GPU y compilador.

## Problemas encontrados y soluciones

### ‚úÖ Instalaci√≥n de CUDA Toolkit

- Ten√≠a instalado **CUDA 11.8 Toolkit** ‚Üí incluye Thrust, no se requiere instalaci√≥n adicional.
- Sin embargo, **no es suficiente solo CUDA Toolkit**:  
  Se necesita un compilador compatible (Visual Studio + cl.exe) en Windows.

---

### ‚ö† Problema 1: `nvcc fatal : Cannot find compiler 'cl.exe' in PATH`

- Falta agregar Visual Studio C++ Build Tools al PATH.
- Soluci√≥n:
    - Usar **Visual Studio Developer Command Prompt 2019**.
    - O pasar `--compiler-bindir` expl√≠cito:
      ```bash
      nvcc vector.cu -o vector.exe --compiler-bindir "C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx64\x64"
      ```

---

### ‚ö† Problema 2: `unsupported Microsoft Visual Studio version`

- CUDA 11.8 no soporta Visual Studio 2022.
- Soluci√≥n:
    - Instalar **Visual Studio 2019 Community Edition**.
    - Usar el Developer Command Prompt de 2019.

---

### ‚ö† Problema 3: `cudaErrorNoKernelImageForDevice`

- El ejecutable compilaba, pero al correr daba:
  ```
  Error al ordenar en dispositivo: radix_sort: failed on 1st step: cudaErrorNoKernelImageForDevice
  ```
- Causa:
    - Mi GPU **GeForce 940MX** tiene arquitectura `sm_50` (Maxwell),  
      no compatible por defecto con binarios de CUDA 11.8.
- Soluci√≥n:
    - Compilar agregando el flag:
      ```bash
      nvcc vector.cu -o vector.exe --compiler-bindir "..." -arch=sm_50
      ```
    - Alternativa: instalar **CUDA Toolkit 11.4 o 10.2**.

---

## Conclusi√≥n

- **¬øNecesit√© instalar algo adicional?**  
  ‚û• S√≠:
  - Visual Studio 2019 (compatible con CUDA 11.8)
  - Compilar con `-arch=sm_50` para soportar mi GPU (940MX).

- **¬øThrust viene con CUDA?**  
  ‚û• S√≠, viene incluido. Pero dependencias externas (compilador, arquitectura GPU) pueden romper la compilaci√≥n/ejecuci√≥n.

---

## Resumen de consideraciones

- Verificar con `nvidia-smi` la arquitectura y versi√≥n CUDA.
- Revisar compatibilidad entre CUDA Toolkit, Visual Studio y GPU.
- Probar con versiones anteriores de CUDA si aparecen errores de ejecuci√≥n.

---

# üí• Sobre Thrust y por qu√© se necesita

**Thrust** es una biblioteca de C++ para CUDA que funciona como una especie de ‚ÄúSTL paralelo‚Äù, es decir, trae contenedores (como `host_vector`, `device_vector`) y algoritmos (como `sort`, `reduce`, `transform`) ya preparados para correr en la GPU, sin que tengamos que escribir kernels CUDA manualmente.

Cuando program√°s **CUDA ‚Äúa pelo‚Äù**, vos te encarg√°s de todo:
- Escrib√≠s tus kernels (`__global__` o `__device__`)
- Organiz√°s los bloques e hilos
- Hac√©s manualmente las copias de memoria entre host y device (`cudaMemcpy`)
- Manej√°s el layout de memoria y optimiz√°s acceso
- Control√°s sincronizaciones y errores

Con **Thrust** eso cambia bastante:
- Us√°s containers como `device_vector` o `host_vector` en lugar de manejar punteros y `cudaMalloc`.
- Llam√°s a algoritmos de alto nivel (`thrust::sort`, `thrust::reduce`, `thrust::transform`) que ya hacen todo el trabajo paralelo internamente.
- Ahorr√°s mucho c√≥digo repetitivo.

### ‚úÖ ¬øQu√© es lo nuevo que se necesita para correr este programa?
Necesit√°s tener disponible Thrust, que viene inclu√≠do en el CUDA Toolkit a partir de CUDA 4.0 (en mi caso CUDA 11.8 ya lo trae).  
No hay que instalar nada adicional, pero s√≠ compilar con `nvcc` y asegurarte de que la GPU soporte los kernels que usa Thrust (a nosotros nos tiro `cudaErrorNoKernelImageForDevice` porque la GPU no es compatible).

### üîë Resumen de diferencia clave
- **CUDA ‚Äúa pelo‚Äù ‚Üí** M√°ximo control, m√°xima responsabilidad.
- **Thrust ‚Üí** Menos c√≥digo, m√°s abstracto, menos optimizable a mano, ideal para prototipos o problemas conocidos (sorting, scan, reduce, etc).
